{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pymysql\n",
    "pymysql.install_as_MySQLdb()\n",
    "import requests\n",
    "import difflib\n",
    "from splinter import Browser\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, inspect, func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of .csv files from kaggle\n",
    "kaggle_list = []\n",
    "path = 'DataFiles/*.csv'\n",
    "\n",
    "for fname in glob.glob(path):\n",
    "    kaggle_list.append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary of df's with kaggle_list as keys and df's from .csv files as values\n",
    "kaggle_dict = {}\n",
    "\n",
    "for file in kaggle_list:\n",
    "    kaggle_dict[os.path.splitext(os.path.basename(file))[0]] = pd.DataFrame(pd.read_csv(file, sep=\",\", encoding='cp1252'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgross\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1007, \"Can't create database 'ncaa_etl_db'; database exists\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x1c25b5404a8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#establish connection and create database\n",
    "engine = create_engine('mysql+pymysql://root:Swoosh!4@localhost')\n",
    "engine.execute('CREATE DATABASE IF NOT EXISTS ncaa_etl_db' )\n",
    "engine.execute(\"USE ncaa_etl_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass dictionary of df's into sql\n",
    "for key, value in kaggle_dict.items():\n",
    "    try:\n",
    "        value.to_sql(key, engine, if_exists = 'replace', index = False)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    except AttributeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup confinguation variables to enable Splinter to interact with browser\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define starting url and pass into Spliter\n",
    "url = 'https://kenpom.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgross\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\jgross\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#create HTML object\n",
    "html = browser.html\n",
    "\n",
    "#iterate through each year's link and create df from html\n",
    "for year in range(2002,2019,1):\n",
    "    url = 'https://kenpom.com/index.php?y=' + str(year)\n",
    "    stats_list = pd.read_html(url)\n",
    "    stats_df = stats_list[0]\n",
    "    \n",
    "    #clean up/rename columns for df\n",
    "    stats_df.columns = stats_df.columns.droplevel(0)\n",
    "    del stats_df.columns.name\n",
    "    stats_df.columns = ['rk', 'TeamName', 'conf', 'w-l', 'adjEM', 'adjO', \n",
    "                        'adjO_r', 'adjD', 'adjD_r', 'adjT', 'adjT_r','luck', \n",
    "                        'luck_r', 'oppEM', 'oppEM_r', 'oppO', 'oppO_r', 'oppD', 'oppD_r', \n",
    "                        'ncsos_adjEM', 'ncsos_adjEM_r']\n",
    "\n",
    "    #cleaned up data within datafram\n",
    "    stats_df_clean = stats_df.dropna(axis = 0, how = 'any')\n",
    "    stats_df_clean['TeamName'] = stats_df_clean['TeamName'].str.replace('\\d+', '')\n",
    "    stats_df_clean['TeamName'] = stats_df_clean['TeamName'].str.replace(' +$', '')\n",
    "    \n",
    "    #use SequenceMatcher to align teams between kaggle and kenpom data sources\n",
    "#         stats_df_clean['merge_TeamName'] = stats_df_clean['TeamName']\n",
    "#         for team_a in stats_df_clean['TeamName'].values:\n",
    "#             for ixb, team_b in enumerate(kaggle_dict['Teams']['TeamName'].values):\n",
    "#                 if difflib.SequenceMatcher(None,team_a,team_b).ratio() > .95:\n",
    "#                     kaggle_dict['Teams'].ix[ixb,'merge_TeamName'] = team_a\n",
    "    \n",
    "    #joint kaggle and kenpom data sources (Teams df) based on team name\n",
    "    stats_df_joined = pd.merge(stats_df_clean, kaggle_dict['Teams'], on = 'TeamName', how = 'left')\n",
    "\n",
    "    #drop all columns added to kenpom data except for teamID which will be used to make schema work across all the kaggle data\n",
    "    stats_df_final = stats_df_joined.drop(['FirstD1Season', 'LastD1Season'], axis = 1)\n",
    "\n",
    "    #pass final df into sql titled by year\n",
    "    try:\n",
    "        stats_df_final.to_sql('kenpom_' + str(year), engine, if_exists = 'replace', index = False)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    except AttributeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = automap_base()\n",
    "try:\n",
    "    Base.prepare(engine, reflect = True)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
